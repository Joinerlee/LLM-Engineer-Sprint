{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c242966",
   "metadata": {},
   "source": [
    "#### Batch Normalization\n",
    "\n",
    "딥러닝 학습할 때 각 Layer를 거치면서 데이터의 분포가 계속 변한다. \n",
    "\n",
    "##### Problem of Deep Neural Network (DNN)\n",
    "\n",
    "- Q. Layer을 깊게 쌓으면 좋아지는 거 아니야?\n",
    "\n",
    "    - 현실 : 깊어질수록 학습이 오히려 안 되거나, 아주 느려지는 형상 발생\n",
    "    - 원인: 데이터가 네트워크를 통과할수록 그 `분포(Distribution)`가 제멋대로 널뛰기 때문.\n",
    "\n",
    "- P. 기울기 소실과 폭발(Vanishing & Exploding)\n",
    "    \n",
    "    - Layer를 거칠 때마다 입력갑 $x$가 $W$(가중치)가 곱해짐`\n",
    "\n",
    "\n",
    "입력: x (배치 데이터) [batch_size, num_features]\n",
    "\n",
    "1. 배치 평균 계산:\n",
    "   $μ = (1/m) * Σ(x_i)$\n",
    "   `m = batch_size`, 각 feature별로 평균 구하기\n",
    "\n",
    "2. 배치 분산 계산:\n",
    "   $σ² = (1/m) * Σ(x_i - μ)²$\n",
    "   각 feature별로 분산 구하기\n",
    "\n",
    "3. 정규화 (Normalization):\n",
    "   $x̂ = (x - μ) / √(σ² + ε)$\n",
    "   ε(엡실론)은 0으로 나누는 것 방지 (1e-5)\n",
    "\n",
    "4. 스케일 & 시프트:\n",
    "   $y = γ * x̂ + β$\n",
    "   $γ$(gamma)는 scale, $β$(beta)는 shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1cec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class BatchNorm:\n",
    "    def __init__(self, num_features):\n",
    "        # num_features : feature 갯수 (Linear의 out_features)\n",
    "        self.num_features = num_features\n",
    "        self.eps = 1e-5\n",
    "\n",
    "        # 학습 가능한 파라미터\n",
    "        self.gemma = [1.0]*num_features #Scale\n",
    "        self.beta = [0.0]*num_features  #Shift\n",
    "\n",
    "        # Backwward를 위한 캐시 변수들\n",
    "        self.x = None\n",
    "        self.x_normalized = None\n",
    "        self.mu = None\n",
    "        self.var = None\n",
    "        self.std = None\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x : Tensor, Shape [batch_size, num_features]\n",
    "        batch_size = len(x)\n",
    "\n",
    "        # 1. 배치 평균 계산 (각 feature 별로)\n",
    "        self.mu = []\n",
    "        for j in range (len(self.x)):\n",
    "            sum_val = 0\n",
    "            for i in range(len(self.x[0])):\n",
    "                sum_val += self[i][j]\n",
    "            mu=sum_val/(len(self.x[0]))\n",
    "            self.mu.append(mu)\n",
    "        \n",
    "        # 2. 배치 분산 계산 (각 feature별로)\n",
    "        self.var = []\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406a9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
